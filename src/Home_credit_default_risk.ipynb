{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from utils.storage import get_storage\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_df = pd.read_csv('./data/application_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_test_df = pd.read_csv('./data/application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_df = pd.read_csv('./data/bureau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_df = pd.read_csv('./data/bureau_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(application_train_df.info())\n",
    "print(application_train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance_pivot_mean_df = bureau_balance_df.pivot_table(index='SK_ID_BUREAU', values='MONTHS_BALANCE', aggfunc=np.mean, fill_value=0)\n",
    "bureau_balance_pivot_len_df = bureau_balance_df.drop('MONTHS_BALANCE', axis='columns').pivot_table(index='SK_ID_BUREAU', columns='STATUS', aggfunc=len, fill_value=0)\n",
    "bureau_balance_pivot_df = pd.concat([bureau_balance_pivot_mean_df, bureau_balance_pivot_len_df], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_mered_df = bureau_df.merge(bureau_balance_pivot_df, how='left', on='SK_ID_BUREAU')\n",
    "bureau_pivot_mean_df_columns = ['SK_ID_CURR','DAYS_CREDIT','CREDIT_DAY_OVERDUE','DAYS_CREDIT_ENDDATE','DAYS_ENDDATE_FACT','AMT_CREDIT_MAX_OVERDUE','CNT_CREDIT_PROLONG','AMT_CREDIT_SUM','AMT_CREDIT_SUM_DEBT','AMT_CREDIT_SUM_LIMIT','AMT_CREDIT_SUM_OVERDUE','DAYS_CREDIT_UPDATE','AMT_ANNUITY']\n",
    "bureau_pivot_mean_df_columns = bureau_pivot_mean_df_columns + bureau_balance_pivot_df.columns.tolist()\n",
    "bureau_pivot_mean_df = bureau_mered_df[bureau_pivot_mean_df_columns].pivot_table(index='SK_ID_CURR', aggfunc=np.mean, fill_value=0)\n",
    "bureau_pivot_CREDIT_ACTIVE_df = bureau_mered_df[['SK_ID_CURR','CREDIT_ACTIVE']].pivot_table(index='SK_ID_CURR', columns='CREDIT_ACTIVE', aggfunc=len, fill_value=0)\n",
    "bureau_pivot_CREDIT_TYPE_df = bureau_mered_df[['SK_ID_CURR','CREDIT_TYPE']].pivot_table(index='SK_ID_CURR', columns='CREDIT_TYPE', aggfunc=len, fill_value=0)\n",
    "bureau_pivot_df = pd.concat([bureau_pivot_mean_df, bureau_pivot_CREDIT_ACTIVE_df, bureau_pivot_CREDIT_TYPE_df], axis='columns')\n",
    "bureau_pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = application_train_df['TARGET']\n",
    "train_df = application_train_df.merge(bureau_pivot_df, how='left', on='SK_ID_CURR')\n",
    "train_df = train_df.drop(['SK_ID_CURR','TARGET'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_df(i_df):\n",
    "    train_df = i_df.copy()\n",
    "    for column in train_df.columns:\n",
    "        # categorical\n",
    "        if train_df[column].dtype == 'object':\n",
    "            # missing values\n",
    "            if train_df[column].isnull().sum() > 0:\n",
    "                train_df[column] = train_df[column].fillna('other')\n",
    "            # label or one hot encoder\n",
    "            if len(train_df[column].unique()) < 20:\n",
    "                one_hot = pd.get_dummies(train_df[column], prefix=column)\n",
    "                train_df = train_df.drop([column], axis='columns')\n",
    "                train_df = train_df.join(one_hot)\n",
    "            else:\n",
    "                labelEncoder = LabelEncoder()\n",
    "                train_df[column] = labelEncoder.fit_transform(train_df[column])\n",
    "        elif train_df[column].dtype != 'object':\n",
    "            if train_df[column].isnull().sum() > 0:\n",
    "                train_df[column] = train_df[column].fillna(0)\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_train_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = XGBClassifier(objective='binary:logistic', eval_metric='auc', random_state=1234)\n",
    "# test_model.fit(X, y)\n",
    "# feature_importance = pd.DataFrame(test_model.feature_importances_, columns=[\"importance\"], index=X.columns)\n",
    "# feature_importance.sort_values(\"importance\", ascending=False).plot(kind=\"bar\", figsize=(100, 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "# important_feature = feature_importance.sort_values(\"importance\", ascending=False)[0:190]\n",
    "# print(len(important_feature))\n",
    "# print(important_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[important_feature.index.tolist()]\n",
    "#print(type(important_feature.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # search better model from RandomForestRegressor, XGBRegressor\n",
    "    regressor_name = trial.suggest_categorical('classifier', ['RandomForest', 'XGBoost'])\n",
    "    # search better max_depth from 2 to 16\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 16)\n",
    "    # search better n_estimators from 50 to 4000\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 4000)\n",
    "    if regressor_name == 'RandomForest':\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=1234)\n",
    "    else:\n",
    "        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, objective='binary:logistic', eval_metric='auc', random_state=1234)\n",
    "\n",
    "    \n",
    "    \n",
    "    error_list = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "\n",
    "    return error_list.mean()  # An objective value linked with the Trial object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', study_name='home_credit_default_risk2', storage=get_storage(), load_if_exists=True)  # Create a new study.\n",
    "study.optimize(objective, n_trials=50)  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-summary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
